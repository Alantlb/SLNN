{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bc-aeuxSGK9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, Input, Flatten, Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnCdDtyPSGK_"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train/255, x_test/255\n",
        "y_train, y_test = tf.one_hot(y_train, 10), tf.one_hot(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcgefL27SfdH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import functools\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, InputLayer\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "class Fow(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @classmethod\n",
        "    def build(self, func):\n",
        "        @functools.wraps(func)\n",
        "        def wrapper(self, input_shapes):\n",
        "            \n",
        "            input_shape = input_shapes[0]\n",
        "            \n",
        "            func(self, input_shape)\n",
        "\n",
        "            self.weights_trainable = []\n",
        "            self.weights_update = []\n",
        "            for weight in self.weights:\n",
        "                if weight.trainable:\n",
        "                    self.weights_trainable.append(weight)\n",
        "                    self.weights_update.append(tf.Variable(weight, trainable=False))\n",
        "\n",
        "            self.prev_inp = tf.Variable(tf.zeros(input_shape), trainable=False)\n",
        "\n",
        "        return wrapper\n",
        "\n",
        "    @classmethod\n",
        "    def call(self, func):\n",
        "        @functools.wraps(func)\n",
        "        def wrapper(self, inp, training=False):\n",
        "\n",
        "            x, grad = inp\n",
        "\n",
        "            weights = []\n",
        "\n",
        "            if training: \n",
        "\n",
        "                for weight, weight_update, dw in zip(self.weights_trainable, self.weights_update, grad):\n",
        "                    weight.assign(weight_update)\n",
        "                    w = weight + dw\n",
        "                    weights.append(w)\n",
        "                    weight_update.assign(w)\n",
        "\n",
        "                self.prev_inp.assign(x)\n",
        "            \n",
        "            else:\n",
        "                weights = self.weights_trainable\n",
        "\n",
        "            return func(self, x, weights, training)\n",
        "        \n",
        "        return wrapper\n",
        "\n",
        "class Back(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.grad = []\n",
        "\n",
        "class FowBack(tf.keras.layers.Layer):\n",
        "    def __init__(self, foward, backward):\n",
        "        super().__init__()\n",
        "        self.foward = foward\n",
        "        self.backward = backward\n",
        "\n",
        "    def call(self, inp, backward=False, training=False):\n",
        "        if backward:\n",
        "            return self.backward([inp, self.foward.weights_trainable, self.foward.prev_inp])\n",
        "        else:\n",
        "            return self.foward([inp, self.backward.grad], training=training) \n",
        "\n",
        "class FowBackModel(tf.keras.Model):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self._layers = layers\n",
        "        self.builds()\n",
        "\n",
        "        batch_size = layers[0].batch_size\n",
        "        out_dim = self.trainable_weights[-1].shape[-1]\n",
        "        self.last_y = tf.Variable(tf.zeros([batch_size, out_dim]), trainable=False)\n",
        "        self.last_pred = tf.Variable(tf.zeros([batch_size, out_dim]), trainable=False)\n",
        "\n",
        "    def builds(self):\n",
        "        self(np.zeros(self.layers[0].output_shape[0]))\n",
        "\n",
        "    @property\n",
        "    def layers(self):\n",
        "        return self._layers\n",
        "    \n",
        "    def call(self, inputs, training=False):\n",
        "        \n",
        "        x = self._layers[0](inputs)\n",
        "\n",
        "        if training:\n",
        "            back = self.last_y - self.last_pred\n",
        "            for layer in reversed(self._layers[1:]):\n",
        "                if 'fow_back' in layer.name:\n",
        "                    back = layer(back, backward=True)\n",
        "        \n",
        "        for layer in self._layers[1:]:\n",
        "            x = layer(x, training=training)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        if len(data) == 3:\n",
        "            x, y, sample_weight = data\n",
        "        else:\n",
        "            sample_weight = None\n",
        "            x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            loss = self.compiled_loss(y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses)\n",
        "        \n",
        "        self.last_y.assign(y)\n",
        "        self.last_pred.assign(y_pred)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "class FowDense(Fow):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "        self.initializer = tf.keras.initializers.GlorotUniform()\n",
        "    \n",
        "    @Fow.build\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=[input_shape[-1], self.n], initializer=self.initializer, trainable=True)\n",
        "        self.b = self.add_weight(shape=[self.n], initializer='zeros', trainable=True)\n",
        "    \n",
        "    @Fow.call\n",
        "    def call(self, x, weights, training=False):\n",
        "        w, b = weights\n",
        "        return x @ w + b\n",
        "\n",
        "class BackDense(Back):\n",
        "    def __init__(self, n, learning_rate=0):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "        self.learning_rate = learning_rate\n",
        "        self.initializer = tf.keras.initializers.GlorotUniform()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.w = tf.Variable(self.initializer([self.n, input_shape[0][-1]]), trainable=False)\n",
        "        # self.grad = tf.Variable(self.dense.output_shape[1:], trainable=False)\n",
        "        pass\n",
        "\n",
        "    def call(self, inp):\n",
        "        chain_grad, weights, prev_inp = inp\n",
        "        w, b = weights\n",
        "        self.w.assign(w)\n",
        "        \n",
        "        # chain_grad = self.dense(chain_grad)\n",
        "        \n",
        "        prev_inp_e = tf.expand_dims(prev_inp, axis=-1)\n",
        "        chain_grad_e = tf.expand_dims(chain_grad, axis=1)\n",
        "\n",
        "        dw = tf.reduce_mean(prev_inp_e @ chain_grad_e, axis=0)\n",
        "        dw = dw * self.learning_rate\n",
        "        \n",
        "        db = tf.reduce_mean(chain_grad, axis=0)\n",
        "        db = db * self.learning_rate\n",
        "\n",
        "        self.grad = [dw, db]\n",
        "        \n",
        "        chain_grad = chain_grad @ tf.transpose(self.w)\n",
        "\n",
        "        return chain_grad\n",
        "\n",
        "class FowRelu(Fow):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    @Fow.build\n",
        "    def build(self, input_shape):\n",
        "        pass\n",
        "    \n",
        "    @Fow.call\n",
        "    def call(self, x, weights, training=False):\n",
        "        return tf.maximum(x, 0)\n",
        "\n",
        "class BackRelu(Back):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        pass\n",
        "\n",
        "    def call(self, inp):\n",
        "        chain_grad, weights, prev_inp = inp\n",
        "        \n",
        "        return chain_grad * tf.maximum(prev_inp, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvY7iaINSGLA",
        "outputId": "9d9dd8e6-f86f-4982-a1b0-51e4c0c1b499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = FowBackModel((\n",
        "    InputLayer((28, 28), batch_size=32),\n",
        "    Flatten(),\n",
        "    FowBack(FowDense(128), BackDense(784)),\n",
        "    FowBack(FowRelu(), BackRelu()),\n",
        "    FowBack(FowDense(10), BackDense(128)),\n",
        "    Activation('softmax')\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Viwc2AOVbuuV",
        "outputId": "06947bf1-65d1-4d8b-f500-a455ae72589b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'fow_back_model/fow_back/fow_dense/Variable:0' shape=(784, 128) dtype=float32, numpy=\n",
              " array([[-0.00945815, -0.02329049, -0.01490351, ...,  0.06388699,\n",
              "          0.05249404, -0.02342992],\n",
              "        [ 0.0017712 ,  0.00118714,  0.05955144, ..., -0.01236433,\n",
              "          0.03673445,  0.04385818],\n",
              "        [-0.06888115, -0.01985686,  0.0357481 , ..., -0.05697545,\n",
              "          0.05334226, -0.05025539],\n",
              "        ...,\n",
              "        [-0.07005154, -0.05987211,  0.059344  , ...,  0.02526644,\n",
              "          0.06492225,  0.02652292],\n",
              "        [ 0.00087293, -0.07608298, -0.01250216, ..., -0.06386201,\n",
              "          0.03524765, -0.06769297],\n",
              "        [-0.05166741,  0.06980281,  0.07097396, ...,  0.02213468,\n",
              "         -0.01319141,  0.01672918]], dtype=float32)>,\n",
              " <tf.Variable 'fow_back_model/fow_back/fow_dense/Variable:0' shape=(128,) dtype=float32, numpy=\n",
              " array([-1.3663010e-04,  2.2185789e-03,  1.8914131e-03,  1.4470483e-03,\n",
              "        -3.0852724e-03, -9.1923086e-04,  1.3057167e-03, -1.2181591e-03,\n",
              "         1.7798863e-03, -4.3264471e-04,  1.2873610e-03,  2.3896960e-04,\n",
              "         4.7866791e-04,  1.0391739e-03, -1.5168533e-03, -1.2064234e-03,\n",
              "         2.1036628e-03,  6.4628728e-04,  1.3478696e-03, -9.1169367e-04,\n",
              "        -1.5488953e-03, -1.0931517e-03,  2.1103942e-03, -2.0589984e-03,\n",
              "        -2.6926803e-03,  1.6491648e-03, -1.7295558e-03,  1.4163897e-03,\n",
              "        -2.7475997e-03,  3.3108708e-03, -3.8778300e-05,  1.5347608e-03,\n",
              "        -5.6439772e-04, -3.3772862e-04, -5.7691784e-04, -2.9718594e-04,\n",
              "         4.2866784e-04,  3.2312342e-03, -6.2606524e-04, -1.1874936e-03,\n",
              "        -2.9528332e-03,  3.2625429e-03,  6.3279219e-04,  1.7589979e-03,\n",
              "        -2.0536676e-03,  2.1724026e-04, -2.4402465e-03,  6.3111342e-04,\n",
              "        -8.7526732e-04, -1.1580484e-03,  7.0207001e-04, -2.4901142e-03,\n",
              "        -3.8218676e-04, -1.0470428e-03,  4.7469465e-04, -1.4786326e-03,\n",
              "         4.4487612e-04,  1.4152579e-03, -5.0922171e-03, -1.1381900e-03,\n",
              "        -3.5612937e-04, -2.9152233e-04,  2.5556169e-03,  1.6082394e-03,\n",
              "         1.3414335e-03,  6.5991090e-04, -1.8637710e-03,  5.2677642e-04,\n",
              "         1.9822749e-03,  6.5121235e-04, -1.9142501e-03,  3.6490790e-04,\n",
              "        -2.9286733e-04,  2.2435840e-03, -2.2643318e-03,  9.6023123e-04,\n",
              "         3.5037193e-04, -2.4181192e-03, -1.9602713e-03, -2.3235065e-04,\n",
              "        -1.8091127e-04,  2.3181995e-03, -1.9720076e-03, -1.6020676e-03,\n",
              "        -5.6482077e-04, -2.8588546e-03,  2.4182329e-04,  2.9120042e-03,\n",
              "        -1.3665690e-03,  1.7242375e-03, -1.8245291e-03,  1.8870905e-03,\n",
              "        -2.2993177e-04, -1.9035519e-03,  2.9058468e-03,  2.9084194e-04,\n",
              "         2.5304761e-03, -1.2585856e-03,  4.8819624e-04, -9.2528568e-04,\n",
              "         7.4242533e-04,  4.4846642e-03,  2.2799334e-04, -2.0152996e-03,\n",
              "        -8.8695082e-04,  6.7871867e-04,  1.2487503e-03, -9.1866631e-04,\n",
              "        -1.8406328e-03, -2.6108157e-03, -9.6555444e-04,  3.4605719e-03,\n",
              "        -2.6631723e-03,  6.0910772e-04,  2.7133664e-03, -3.6977179e-04,\n",
              "         1.4514277e-03, -7.0415692e-05,  2.3463415e-04,  4.2396178e-04,\n",
              "         4.5304792e-03,  9.5210318e-04,  3.7328596e-04,  2.1183752e-03,\n",
              "         1.2634866e-04,  2.5476492e-03,  2.9313660e-03, -2.1239610e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'fow_back_model/fow_back/back_dense/Variable:0' shape=(784, 128) dtype=float32, numpy=\n",
              " array([[-0.00945815, -0.02329049, -0.01490351, ...,  0.06388699,\n",
              "          0.05249404, -0.02342992],\n",
              "        [ 0.0017712 ,  0.00118714,  0.05955144, ..., -0.01236433,\n",
              "          0.03673445,  0.04385818],\n",
              "        [-0.06888115, -0.01985686,  0.0357481 , ..., -0.05697545,\n",
              "          0.05334226, -0.05025539],\n",
              "        ...,\n",
              "        [-0.07005154, -0.05987211,  0.059344  , ...,  0.02526644,\n",
              "          0.06492225,  0.02652292],\n",
              "        [ 0.00087293, -0.07608298, -0.01250216, ..., -0.06386201,\n",
              "          0.03524765, -0.06769297],\n",
              "        [-0.05166741,  0.06980281,  0.07097396, ...,  0.02213468,\n",
              "         -0.01319141,  0.01672918]], dtype=float32)>,\n",
              " <tf.Variable 'fow_back_model/fow_back_2/fow_dense_1/Variable:0' shape=(128, 10) dtype=float32, numpy=\n",
              " array([[ 0.09027916,  0.13746184, -0.10277691, ...,  0.15491693,\n",
              "         -0.07954315, -0.12938377],\n",
              "        [-0.05006643, -0.13065945, -0.00293405, ...,  0.00819922,\n",
              "          0.21227562,  0.05462575],\n",
              "        [ 0.0446978 , -0.15360336, -0.176982  , ...,  0.11337235,\n",
              "         -0.08060481, -0.09052306],\n",
              "        ...,\n",
              "        [-0.05065088, -0.06407082, -0.18680385, ..., -0.01666139,\n",
              "          0.18493108, -0.04583312],\n",
              "        [-0.15415119,  0.0021157 ,  0.17269127, ...,  0.16003035,\n",
              "         -0.14317611,  0.1285244 ],\n",
              "        [ 0.1812577 , -0.0440072 , -0.05394521, ..., -0.0732632 ,\n",
              "          0.02894441, -0.17158613]], dtype=float32)>,\n",
              " <tf.Variable 'fow_back_model/fow_back_2/fow_dense_1/Variable:0' shape=(10,) dtype=float32, numpy=\n",
              " array([-0.00928452,  0.00988518, -0.00466455, -0.00763627,  0.00701052,\n",
              "        -0.00626808,  0.00179583,  0.0025362 ,  0.00326955,  0.00335615],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'fow_back_model/fow_back_2/back_dense_1/Variable:0' shape=(128, 10) dtype=float32, numpy=\n",
              " array([[ 0.09051435,  0.13759422, -0.10195162, ...,  0.15371138,\n",
              "         -0.08047466, -0.12950587],\n",
              "        [-0.04876864, -0.13007176,  0.00232329, ...,  0.00853709,\n",
              "          0.2133367 ,  0.05169063],\n",
              "        [ 0.04439803, -0.15349564, -0.175003  , ...,  0.11237954,\n",
              "         -0.08080725, -0.09045953],\n",
              "        ...,\n",
              "        [-0.04932799, -0.06395467, -0.17911533, ..., -0.01827315,\n",
              "          0.18333326, -0.04919506],\n",
              "        [-0.1519647 ,  0.00166738,  0.17732072, ...,  0.15820944,\n",
              "         -0.14245144,  0.12643966],\n",
              "        [ 0.18303898, -0.04400059, -0.05376893, ..., -0.07437228,\n",
              "          0.02898349, -0.17270643]], dtype=float32)>]"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.trainable_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0U1F8AcSPhN",
        "outputId": "41ac07b7-71b0-4202-e6dc-909da6344384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2965 - accuracy: 0.9150 - val_loss: 0.1752 - val_accuracy: 0.9462\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1444 - accuracy: 0.9583 - val_loss: 0.1166 - val_accuracy: 0.9654\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1048 - accuracy: 0.9689 - val_loss: 0.1046 - val_accuracy: 0.9676\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0827 - accuracy: 0.9757 - val_loss: 0.0849 - val_accuracy: 0.9731\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0681 - accuracy: 0.9807 - val_loss: 0.0821 - val_accuracy: 0.9740\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae44d4af10>"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=SGD(1e-1), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h-O4lXUSfM9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
